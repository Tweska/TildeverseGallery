#!/usr/bin/env python3

# Name:         update
# Author:       ~tweska
# Description:  Program used to update the gallery.


from sys import stderr
import subprocess
import time
from datetime import datetime, timezone
import os
import zipfile
import json

import click
from jinja2 import Template


SCRIPT_TIMESTAMPS = 'remote/timestamps.sh'
SCRIPT_UNPACK = 'remote/unpack.sh'
FILE_PERMISSIONS = 0o644


def create_dir(path):
    if os.path.isfile(path):
        print(f"'{path}' is a file!", file=stderr)
        exit(-1)
    if not os.path.isdir(path):
        os.makedirs(path)


def get_users(host):
    # Read the bash program from the file.
    path = os.path.join(os.path.dirname(__file__), SCRIPT_TIMESTAMPS)
    script = open(path, 'r').read()

    # Execute the program in a remote shell.
    reply = subprocess.run(
        ['ssh', host, script],
        capture_output=True,
        encoding='UTF-8',
    ).stdout

    # Convert the output into a list of dictionaries.
    result = []
    for (t, p) in [l.split(' ') for l in reply.strip().split('\n')]:
        result.append({
            'username': p.split('/')[2],
            'timestamp': int(float(t)),
        })
    return result


def merge_users(cached_users, new_users):
    for new_user in new_users:
        # Find the user in the cache file.
        cached_user = next((u for u in cached_users
                            if u['username'] == new_user['username']), None)

        # Skip merging if user is new.
        if not cached_user:
            continue

        # Merge cached and new user entry.
        for key in cached_user.keys():
            if key in ['username', 'timestamp']:
                continue
            new_user[key] = cached_user[key]

    return new_users


def take_screenshot(url, path):
    # Spawn a new process to take the screenshot and obtain a hash.
    program = os.path.join(os.path.dirname(__file__), 'screenshot')
    try:
        process = subprocess.run(
            ['timeout', '-s', '9', '30', program, url, '-p', path, '-r', '400,300', '-h'],
            capture_output=True,
            encoding='UTF-8',
        )
    except Exception:
        return (False, "")
    return (process.returncode == 0, process.stdout.strip())


def update_outdated(users, prev_update, default_hashes, base_url, out_path):
    for user in users:
        # Skip unchanged page, except if fields are missing.
        if all([k in user for k in ['timestamp', 'hash', 'default', 'error']])\
                and user['timestamp'] < prev_update:
            continue

        print(f"Updating {user['username']} ... ", end="", file=stderr)
        stderr.flush()

        # Take a (new) screenshot.
        url = f"{base_url}/~{user['username']}/"
        path = f"{out_path}/screenshots/{user['username']}.png"
        success, hash = take_screenshot(url, path)

        # Save obtained data.
        user['hash'] = hash
        user['default'] = hash in default_hashes
        user['error'] = not success

        # Write status message.
        status = []
        if (user['error']):
            status.append("Error")
        else:
            status.append("Success")
        if (user['default']):
            status.append("Default")
        print(f"{', '.join(status)}!", file=stderr)

        # Early return if not a default page.
        if not user['default']:
            continue

        # Remove screenshot of default page.
        if os.path.exists(path):
            os.remove(path)
        if os.path.exists(path[:-4] + '-thumbnail' + path[-4:]):
            os.remove(path[:-4] + '-thumbnail' + path[-4:])


def generate_site(users, timestamp, template_path, out_path, single=False):
    # Sort users into 27 bins.
    if not single:
        users_bins = {k: [u for u in users if u['username'][0].upper() == k]
                    for k in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'}
        users_bins['other'] = [u for u in users if not u['username'][0].isalpha()]
    else:
        users_bins = {'index': users}

    # Convert the timestamp into readable text.
    update_time = datetime.fromtimestamp(timestamp, timezone.utc) \
        .strftime("%A %-d %B %Y %H:%M (UTC)")

    # Read template file.
    try:
        with open(f'{template_path}/template.html', 'r') as file:
            template = Template(file.read())
    except Exception:
        print("Could not read template file!", file=stderr)
        exit(-1)

    with zipfile.ZipFile(f'{out_path}/gallery.zip', 'w') as z:
        # Render the template.
        for key in users_bins.keys():
            html = template.render(
                update_time=update_time,
                users=sorted(users_bins[key], key=lambda u: u['username'].upper())
            )
            info = zipfile.ZipInfo(f'{key}.html')
            info.external_attr = FILE_PERMISSIONS << 16
            z.writestr(info, html)

        # Write static files to archive.
        for dir, _, files in os.walk(template_path):
            for file in files:
                org_path = os.path.join(dir, file)
                arc_path = os.path.relpath(org_path, template_path)
                if arc_path != "template.html":
                    os.chmod(org_path, FILE_PERMISSIONS)
                    z.write(org_path, arc_path)

        # Write screenshots to archive.
        for dir, _, files in os.walk(f'{out_path}/screenshots'):
            for file in files:
                org_path = os.path.join(dir, file)
                arc_path = os.path.relpath(org_path, out_path)
                os.chmod(org_path, FILE_PERMISSIONS)
                z.write(org_path, arc_path)


def upload_site(host, out_path):
    # Upload archive to remote server.
    proc = subprocess.run(
        ['scp', f'{out_path}/gallery.zip', f'{host}:~/gallery.zip'],
        capture_output=True,
        encoding='UTF-8',
    )
    if proc.returncode != 0:
        print("Failed to upload to remote server!", file=stderr)
        exit(-1)

    # Read the bash program from the file.
    path = os.path.join(os.path.dirname(__file__), SCRIPT_UNPACK)
    script = open(path, 'r').read()

    # Execute the program in a remote shell.
    proc = subprocess.run(
        ['ssh', host, script],
        capture_output=True,
        encoding='UTF-8',
    )
    if proc.returncode != 0:
        print("Failed to run command on remote server!", file=stderr)
        exit(-1)


@click.command()
@click.argument('host', type=str)
@click.argument('base_url', type=str)
@click.argument('out_path', type=str)
@click.argument('template_path', type=str)
@click.option('-u', '--upload', is_flag=True, default=False)
@click.option('-s', '--single', is_flag=True, default=False)
def update(host, base_url, out_path, template_path, upload, single):
    # Get the current timestamp.
    timestamp = int(time.time())

    # Create output directories.
    create_dir(out_path)
    create_dir(f'{out_path}/screenshots')

    # Open cache file.
    try:
        with open(f'{out_path}/cache.json', 'r') as file:
            cache = json.load(file)
    except Exception:
        cache = {
            'timestamp': 0,
            'default': [],
            'users': []
        }

    # Get users & timestamps from remote server.
    users = sorted(get_users(host), key=lambda u: u['timestamp'], reverse=True)

    # Merge with cached data.
    users = merge_users(cache['users'], users)

    # Update outdated screenshots.
    update_outdated(users, cache['timestamp'], cache['default'], base_url,
                    out_path)

    # Save cache data.
    cache = {
        'timestamp': timestamp,
        'default': cache['default'],
        'users': users
    }

    try:
        with open(f'{out_path}/cache.json', 'w') as file:
            json.dump(cache, file, indent=4)
    except Exception:
        exit(-1)

    # Generate website.
    generate_site(users, timestamp, template_path, out_path, single)

    # Send to remote server and unzip.
    if upload:
        upload_site(host, out_path)


if __name__ == '__main__':
    update()
