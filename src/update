#!/usr/bin/env python3

# Name:         update
# Author:       ~tweska
# Description:  Program used to update the gallery.


from sys import stderr
import subprocess
import time
import datetime
import os
import zipfile
import json

import click
from jinja2 import Template


SCRIPT_TIMESTAMPS = 'remote/timestamps.sh'


def create_dir(path):
    if os.path.isfile(path):
        print(f"'{path}' is a file!", file=stderr)
        exit(-1)
    if not os.path.isdir(path):
        os.makedirs(path)


def get_users(host):
    # Read the bash program from the file.
    path = os.path.join(os.path.dirname(__file__), SCRIPT_TIMESTAMPS)
    script = open(path, 'r').read()

    # Execute the program in a remote shell.
    reply = subprocess.run(
        ['ssh', host, script],
        capture_output=True,
        encoding='UTF-8',
    ).stdout

    # Convert the output into a list of dictionaries.
    result = []
    for (t, p) in [l.split(' ') for l in reply.strip().split('\n')]:
        result.append({
            'username': p.split('/')[2],
            'timestamp': int(float(t)),
        })
    return result


def merge_users(cached_users, new_users):
    for new_user in new_users:
        # Find the user in the cache file.
        cached_user = next((u for u in cached_users
                            if u['username'] == new_user['username']), None)

        # Skip merging if user is new.
        if not cached_user:
            continue

        # Merge cached and new user entry.
        for key in cached_user.keys():
            if key in ['username', 'timestamp']:
                continue
            new_user[key] = cached_user[key]

    return new_users


def take_screenshot(url, path):
    # Spawn a new process to take the screenshot and obtain a hash.
    program = os.path.join(os.path.dirname(__file__), 'screenshot')
    process = subprocess.run(
        [program, url, '-p', path, '-r', '400,300', '-h'],
        capture_output=True,
        encoding='UTF-8',
    )
    return (process.returncode == 0, process.stdout.strip())


def update_outdated(users, prev_update, default_hashes, base_url, out_path):
    for user in users:
        # Skip unchanged page.
        if user['timestamp'] < prev_update:
            continue

        print(f"Updating {user['username']} ...", file=stderr)

        # Take a (new) screenshot.
        url = f"{base_url}/~{user['username']}/"
        path = f"{out_path}/screenshots/{user['username']}.png"
        success, hash = take_screenshot(url, path)

        # Save obtained data.
        user['hash'] = hash
        user['default'] = hash in default_hashes
        user['error'] = not success

        # Early return if not a default page.
        if not user['default']:
            continue

        # Remove screenshot of default page.
        if os.path.exists(path):
            os.remove(path)
        if os.path.exists(path[:-4] + '-thumbnail' + path[-4:]):
            os.remove(path[:-4] + '-thumbnail' + path[-4:])


def generate_site(users, timestamp, template_path, out_path):
    # Sort users into 27 bins.
    users_bins = {k: [u for u in users if u['username'][0].upper() == k]
                  for k in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'}
    users_bins['other'] = [u for u in users if not u['username'][0].isalpha()]

    # Convert the timestamp into readable text.
    update_time = datetime.datetime.fromtimestamp(timestamp) \
        .strftime("%A %-d %B %Y %H:%M")

    # Read template file.
    try:
        with open(f'{template_path}/template.html', 'r') as file:
            template = Template(file.read())
    except Exception:
        print("Could not read template file!", file=stderr)
        exit(-1)

    with zipfile.ZipFile(f'{out_path}/archive.zip', 'w') as z:
        # Render the template.
        for key in users_bins.keys():
            html = template.render(
                update_time=update_time,
                users=sorted(users_bins[key], key=lambda u: u['username'].upper())
            )
            z.writestr(f'{key}.html', html)

        # Write static files to archive.
        for dir, _, files in os.walk(template_path):
            for file in files:
                org_path = os.path.join(dir, file)
                arc_path = os.path.relpath(org_path, template_path)
                if arc_path != "template.html":
                    z.write(org_path, arc_path)

        # Write screenshots to archive.
        for dir, _, files in os.walk(f'{out_path}/screenshots'):
            for file in files:
                org_path = os.path.join(dir, file)
                arc_path = os.path.relpath(org_path, out_path)
                z.write(org_path, arc_path)


@click.command()
@click.argument('host', type=str)
@click.argument('base_url', type=str)
@click.argument('out_path', type=str)
@click.argument('template_path', type=str)
def update(host, base_url, out_path, template_path):
    # Get the current timestamp.
    timestamp = int(time.time())

    # Create output directories.
    create_dir(out_path)
    create_dir(f'{out_path}/screenshots')

    # Open cache file.
    try:
        with open(f'{out_path}/cache.json', 'r') as file:
            cache = json.load(file)
    except Exception:
        cache = {
            'timestamp': 0,
            'default': [],
            'users': []
        }

    # Get users & timestamps from remote server.
    users = sorted(get_users(host), key=lambda u: u['timestamp'], reverse=True)

    # Merge with cached data.
    users = merge_users(cache['users'], users)

    # Update outdated screenshots.
    update_outdated(users, cache['timestamp'], cache['default'], base_url,
                    out_path)

    # Save cache data.
    cache = {
        'timestamp': timestamp,
        'default': cache['default'],
        'users': users
    }

    try:
        with open(f'{out_path}/cache.json', 'w') as file:
            json.dump(cache, file, indent=4)
    except Exception:
        exit(-1)

    # Generate website.
    generate_site(users, timestamp, template_path, out_path)

    # TODO Send to remote server and unzip.


if __name__ == '__main__':
    update()
